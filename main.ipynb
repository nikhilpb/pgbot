{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de07ab7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import numpy as np\n",
    "import requests\n",
    "import spacy\n",
    "import random\n",
    "import re\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "fa583f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched the articles page.\n",
      "Total articles fetched: 218\n",
      "Finished 10 out of 219 requests\n",
      "Finished 20 out of 219 requests\n",
      "Finished 30 out of 219 requests\n",
      "Finished 40 out of 219 requests\n",
      "Finished 50 out of 219 requests\n",
      "Finished 60 out of 219 requests\n",
      "Finished 70 out of 219 requests\n",
      "Finished 80 out of 219 requests\n",
      "Finished 90 out of 219 requests\n",
      "Finished 100 out of 219 requests\n",
      "Finished 110 out of 219 requests\n",
      "Finished 120 out of 219 requests\n",
      "Finished 130 out of 219 requests\n",
      "Finished 140 out of 219 requests\n",
      "Finished 150 out of 219 requests\n",
      "Finished 160 out of 219 requests\n",
      "Finished 170 out of 219 requests\n",
      "Finished 180 out of 219 requests\n",
      "Finished 190 out of 219 requests\n",
      "Finished 200 out of 219 requests\n",
      "Finished 210 out of 219 requests\n",
      "total_success: 217, total_failure: 2\n"
     ]
    }
   ],
   "source": [
    "# Fetching all essay webpages\n",
    "\n",
    "BASE_URL = 'http://www.paulgraham.com/'\n",
    "ARTICLES_URL = BASE_URL + 'articles.html'\n",
    "BASE_URL\n",
    "response = requests.get(ARTICLES_URL)\n",
    "if response.status_code == 200:\n",
    "    print('Fetched the articles page.')\n",
    "else:\n",
    "    print(f'Request failed with code {response.status_code}')\n",
    "\n",
    "pgsoup = BS(response.text, 'lxml')\n",
    "print(f\"Total articles fetched: {len(pgsoup.select('a')[1:])}\")\n",
    "\n",
    "all_links = [BASE_URL + link.get('href') for link in pgsoup.find_all('a')]\n",
    "success = 0\n",
    "failure = 0\n",
    "finished_requests = 0\n",
    "all_pages = []\n",
    "total_requests = len(all_links)\n",
    "for link in all_links:\n",
    "    finished_requests = finished_requests + 1\n",
    "    rs = requests.get(link)\n",
    "    if finished_requests % 10 == 0:\n",
    "        print(f'Finished {finished_requests} out of {total_requests} requests')\n",
    "    if rs.status_code == 200:\n",
    "        success = success + 1\n",
    "        all_pages.append(rs.text)\n",
    "    else: \n",
    "        failure = failure + 1\n",
    "print(f'total_success: {success}, total_failure: {failure}')\n",
    "print(f'Approximately {float(sum([len(t) for t in all_pages])) / (1024 * 1024):.2f} MB of data fetched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "837323bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 20.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from en-core-web-sm==3.4.1) (3.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: jinja2 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: setuptools in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kritikakaul/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_sm')\n",
    "tk = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "deb25a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 2.81 MB of essays\n"
     ]
    }
   ],
   "source": [
    "# Getting a list of essays and tokens\n",
    "essays = [BS(p).find('table') for p in all_pages]\n",
    "essays = [e.text.replace(\"\\'\", \"\").replace(\"\\n\", \" \") for e in essays if (e is not None and len(e.text) >= 500)]\n",
    "tokens = [tk(e)[1:] for e in essays] \n",
    "for t in tokens:\n",
    "    t[0] = t[0][4:]\n",
    "print(f'Approximately {float(sum([len(e) for e in essays])) / (1024 * 1024):.2f} MB of essays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "de4d7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocab\n",
    "def yield_tokens(essays):\n",
    "    for text in essays:\n",
    "        yield tk(text)\n",
    "vocab = build_vocab_from_iterator(yield_tokens(essays), specials=[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "eb5cdbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 492772\n",
      "Validation size: 61597\n",
      "Testing size: 61597\n"
     ]
    }
   ],
   "source": [
    "# Making n-grams\n",
    "EMBED_SIZE = 10\n",
    "CONTEXT_SIZE = 3\n",
    "all_tokens = []\n",
    "for ts in tokens:\n",
    "    for t in ts:\n",
    "        all_tokens.append(t)\n",
    "ngrams = [\n",
    "    (\n",
    "        [all_tokens[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        all_tokens[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(all_tokens))\n",
    "]\n",
    "\n",
    "n1 = int(0.8 * len(ngrams))\n",
    "n2 = int(0.9 * len(ngrams))\n",
    "ngrams_train = ngrams[0:n1]\n",
    "ngrams_valid = ngrams[n1:n2]\n",
    "ngrams_test = ngrams[n2:]\n",
    "print(f'Training size: {len(ngrams_train)}')\n",
    "print(f'Validation size: {len(ngrams_valid)}')\n",
    "print(f'Testing size: {len(ngrams_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1df59751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup NN model\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBED_SIZE, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "dbbabd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 steps done.\n",
      "average loss: 6.65\n",
      "200 steps done.\n",
      "average loss: 6.79\n",
      "300 steps done.\n",
      "average loss: 6.83\n",
      "400 steps done.\n",
      "average loss: 6.79\n",
      "500 steps done.\n",
      "average loss: 6.74\n",
      "600 steps done.\n",
      "average loss: 6.74\n",
      "700 steps done.\n",
      "average loss: 6.85\n",
      "800 steps done.\n",
      "average loss: 6.95\n",
      "900 steps done.\n",
      "average loss: 7.01\n",
      "1000 steps done.\n",
      "average loss: 7.12\n",
      "1100 steps done.\n",
      "average loss: 7.16\n",
      "1200 steps done.\n",
      "average loss: 7.08\n",
      "1300 steps done.\n",
      "average loss: 7.06\n",
      "1400 steps done.\n",
      "average loss: 7.06\n",
      "1500 steps done.\n",
      "average loss: 7.21\n",
      "1600 steps done.\n",
      "average loss: 7.34\n",
      "1700 steps done.\n",
      "average loss: 7.47\n",
      "1800 steps done.\n",
      "average loss: 7.50\n",
      "1900 steps done.\n",
      "average loss: 7.43\n",
      "2000 steps done.\n",
      "average loss: 7.40\n",
      "2100 steps done.\n",
      "average loss: 7.34\n",
      "2200 steps done.\n",
      "average loss: 7.38\n",
      "2300 steps done.\n",
      "average loss: 7.43\n",
      "2400 steps done.\n",
      "average loss: 7.43\n",
      "2500 steps done.\n",
      "average loss: 7.41\n",
      "2600 steps done.\n",
      "average loss: 7.39\n",
      "2700 steps done.\n",
      "average loss: 7.37\n",
      "2800 steps done.\n",
      "average loss: 7.37\n",
      "2900 steps done.\n",
      "average loss: 7.34\n",
      "3000 steps done.\n",
      "average loss: 7.31\n",
      "3100 steps done.\n",
      "average loss: 7.30\n",
      "3200 steps done.\n",
      "average loss: 7.30\n",
      "3300 steps done.\n",
      "average loss: 7.27\n",
      "3400 steps done.\n",
      "average loss: 7.25\n",
      "3500 steps done.\n",
      "average loss: 7.24\n",
      "3600 steps done.\n",
      "average loss: 7.22\n",
      "3700 steps done.\n",
      "average loss: 7.21\n",
      "3800 steps done.\n",
      "average loss: 7.22\n",
      "3900 steps done.\n",
      "average loss: 7.20\n",
      "4000 steps done.\n",
      "average loss: 7.21\n",
      "4100 steps done.\n",
      "average loss: 7.21\n",
      "4200 steps done.\n",
      "average loss: 7.21\n",
      "4300 steps done.\n",
      "average loss: 7.20\n",
      "4400 steps done.\n",
      "average loss: 7.21\n",
      "4500 steps done.\n",
      "average loss: 7.20\n",
      "4600 steps done.\n",
      "average loss: 7.21\n",
      "4700 steps done.\n",
      "average loss: 7.19\n",
      "4800 steps done.\n",
      "average loss: 7.19\n",
      "4900 steps done.\n",
      "average loss: 7.20\n",
      "5000 steps done.\n",
      "average loss: 7.19\n",
      "5100 steps done.\n",
      "average loss: 7.19\n",
      "5200 steps done.\n",
      "average loss: 7.18\n",
      "5300 steps done.\n",
      "average loss: 7.16\n",
      "5400 steps done.\n",
      "average loss: 7.16\n",
      "5500 steps done.\n",
      "average loss: 7.16\n",
      "5600 steps done.\n",
      "average loss: 7.15\n",
      "5700 steps done.\n",
      "average loss: 7.15\n",
      "5800 steps done.\n",
      "average loss: 7.15\n",
      "5900 steps done.\n",
      "average loss: 7.16\n",
      "6000 steps done.\n",
      "average loss: 7.15\n",
      "6100 steps done.\n",
      "average loss: 7.16\n",
      "6200 steps done.\n",
      "average loss: 7.16\n",
      "6300 steps done.\n",
      "average loss: 7.15\n",
      "6400 steps done.\n",
      "average loss: 7.14\n",
      "6500 steps done.\n",
      "average loss: 7.13\n",
      "6600 steps done.\n",
      "average loss: 7.12\n",
      "6700 steps done.\n",
      "average loss: 7.13\n",
      "6800 steps done.\n",
      "average loss: 7.15\n",
      "6900 steps done.\n",
      "average loss: 7.15\n",
      "7000 steps done.\n",
      "average loss: 7.14\n",
      "7100 steps done.\n",
      "average loss: 7.13\n",
      "7200 steps done.\n",
      "average loss: 7.12\n",
      "7300 steps done.\n",
      "average loss: 7.12\n",
      "7400 steps done.\n",
      "average loss: 7.12\n",
      "7500 steps done.\n",
      "average loss: 7.11\n",
      "7600 steps done.\n",
      "average loss: 7.09\n",
      "7700 steps done.\n",
      "average loss: 7.08\n",
      "7800 steps done.\n",
      "average loss: 7.09\n",
      "7900 steps done.\n",
      "average loss: 7.10\n",
      "8000 steps done.\n",
      "average loss: 7.11\n",
      "8100 steps done.\n",
      "average loss: 7.12\n",
      "8200 steps done.\n",
      "average loss: 7.11\n",
      "8300 steps done.\n",
      "average loss: 7.11\n",
      "8400 steps done.\n",
      "average loss: 7.10\n",
      "8500 steps done.\n",
      "average loss: 7.10\n",
      "8600 steps done.\n",
      "average loss: 7.11\n",
      "8700 steps done.\n",
      "average loss: 7.11\n",
      "8800 steps done.\n",
      "average loss: 7.12\n",
      "8900 steps done.\n",
      "average loss: 7.12\n",
      "9000 steps done.\n",
      "average loss: 7.12\n",
      "9100 steps done.\n",
      "average loss: 7.12\n",
      "9200 steps done.\n",
      "average loss: 7.12\n",
      "9300 steps done.\n",
      "average loss: 7.12\n",
      "9400 steps done.\n",
      "average loss: 7.11\n",
      "9500 steps done.\n",
      "average loss: 7.10\n",
      "9600 steps done.\n",
      "average loss: 7.10\n",
      "9700 steps done.\n",
      "average loss: 7.11\n",
      "9800 steps done.\n",
      "average loss: 7.12\n",
      "9900 steps done.\n",
      "average loss: 7.12\n",
      "71200.52058208856\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    for context, target in ngrams_train[0:1000]:\n",
    "        not_found = False \n",
    "        if target not in vocab:\n",
    "            not_found = True\n",
    "        for c in context:\n",
    "            if c not in vocab:\n",
    "                not_found = True\n",
    "        if not_found:\n",
    "            continue\n",
    "        steps = steps + 1\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([vocab[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([vocab[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "        if steps % 100 == 0:\n",
    "            print(f'{steps} steps done.')\n",
    "            print(f'average loss: {total_loss / steps:.2f}')\n",
    "    print(total_loss)\n",
    "    losses.append(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "303651bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    if len(words) != 3:\n",
    "        return ''\n",
    "    input = torch.tensor(vocab(words)[::-1], dtype=torch.long)\n",
    "    logit = model(input)\n",
    "    return vocab.lookup_tokens([torch.argmax(torch.exp(logit))])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "1e307213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next('be a chance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "37cb7945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['some', 'are', 'There'], 'kinds'),\n",
       " (['kinds', 'some', 'are'], 'of'),\n",
       " (['of', 'kinds', 'some'], 'work'),\n",
       " (['work', 'of', 'kinds'], 'that'),\n",
       " (['that', 'work', 'of'], 'you'),\n",
       " (['you', 'that', 'work'], 'ca'),\n",
       " (['ca', 'you', 'that'], 'nt'),\n",
       " (['nt', 'ca', 'you'], 'do'),\n",
       " (['do', 'nt', 'ca'], 'well'),\n",
       " (['well', 'do', 'nt'], 'without'),\n",
       " (['without', 'well', 'do'], 'thinking'),\n",
       " (['thinking', 'without', 'well'], 'differently'),\n",
       " (['differently', 'thinking', 'without'], 'from'),\n",
       " (['from', 'differently', 'thinking'], 'your'),\n",
       " (['your', 'from', 'differently'], 'peers'),\n",
       " (['peers', 'your', 'from'], '.'),\n",
       " (['.', 'peers', 'your'], 'To'),\n",
       " (['To', '.', 'peers'], 'be'),\n",
       " (['be', 'To', '.'], 'a'),\n",
       " (['a', 'be', 'To'], 'successful'),\n",
       " (['successful', 'a', 'be'], 'scientist'),\n",
       " (['scientist', 'successful', 'a'], ','),\n",
       " ([',', 'scientist', 'successful'], 'for'),\n",
       " (['for', ',', 'scientist'], 'example'),\n",
       " (['example', 'for', ','], ','),\n",
       " ([',', 'example', 'for'], 'its'),\n",
       " (['its', ',', 'example'], 'not'),\n",
       " (['not', 'its', ','], 'enough'),\n",
       " (['enough', 'not', 'its'], 'just'),\n",
       " (['just', 'enough', 'not'], 'to'),\n",
       " (['to', 'just', 'enough'], 'be'),\n",
       " (['be', 'to', 'just'], 'correct'),\n",
       " (['correct', 'be', 'to'], '.'),\n",
       " (['.', 'correct', 'be'], 'Your'),\n",
       " (['Your', '.', 'correct'], 'ideas'),\n",
       " (['ideas', 'Your', '.'], 'have'),\n",
       " (['have', 'ideas', 'Your'], 'to'),\n",
       " (['to', 'have', 'ideas'], 'be'),\n",
       " (['be', 'to', 'have'], 'both'),\n",
       " (['both', 'be', 'to'], 'correct'),\n",
       " (['correct', 'both', 'be'], 'and'),\n",
       " (['and', 'correct', 'both'], 'novel'),\n",
       " (['novel', 'and', 'correct'], '.'),\n",
       " (['.', 'novel', 'and'], 'You'),\n",
       " (['You', '.', 'novel'], 'ca'),\n",
       " (['ca', 'You', '.'], 'nt'),\n",
       " (['nt', 'ca', 'You'], 'publish'),\n",
       " (['publish', 'nt', 'ca'], 'papers'),\n",
       " (['papers', 'publish', 'nt'], 'saying'),\n",
       " (['saying', 'papers', 'publish'], 'things'),\n",
       " (['things', 'saying', 'papers'], 'other'),\n",
       " (['other', 'things', 'saying'], 'people'),\n",
       " (['people', 'other', 'things'], 'already'),\n",
       " (['already', 'people', 'other'], 'know'),\n",
       " (['know', 'already', 'people'], '.'),\n",
       " (['.', 'know', 'already'], 'You'),\n",
       " (['You', '.', 'know'], 'need'),\n",
       " (['need', 'You', '.'], 'to'),\n",
       " (['to', 'need', 'You'], 'say'),\n",
       " (['say', 'to', 'need'], 'things'),\n",
       " (['things', 'say', 'to'], 'no'),\n",
       " (['no', 'things', 'say'], 'one'),\n",
       " (['one', 'no', 'things'], 'else'),\n",
       " (['else', 'one', 'no'], 'has'),\n",
       " (['has', 'else', 'one'], 'realized'),\n",
       " (['realized', 'has', 'else'], 'yet'),\n",
       " (['yet', 'realized', 'has'], '.'),\n",
       " (['.', 'yet', 'realized'], 'The'),\n",
       " (['The', '.', 'yet'], 'same'),\n",
       " (['same', 'The', '.'], 'is'),\n",
       " (['is', 'same', 'The'], 'true'),\n",
       " (['true', 'is', 'same'], 'for'),\n",
       " (['for', 'true', 'is'], 'investors'),\n",
       " (['investors', 'for', 'true'], '.'),\n",
       " (['.', 'investors', 'for'], 'Its'),\n",
       " (['Its', '.', 'investors'], 'not'),\n",
       " (['not', 'Its', '.'], 'enough'),\n",
       " (['enough', 'not', 'Its'], 'for'),\n",
       " (['for', 'enough', 'not'], 'a'),\n",
       " (['a', 'for', 'enough'], 'public'),\n",
       " (['public', 'a', 'for'], 'market'),\n",
       " (['market', 'public', 'a'], 'investor'),\n",
       " (['investor', 'market', 'public'], 'to'),\n",
       " (['to', 'investor', 'market'], 'predict'),\n",
       " (['predict', 'to', 'investor'], 'correctly'),\n",
       " (['correctly', 'predict', 'to'], 'how'),\n",
       " (['how', 'correctly', 'predict'], 'a'),\n",
       " (['a', 'how', 'correctly'], 'company'),\n",
       " (['company', 'a', 'how'], 'will'),\n",
       " (['will', 'company', 'a'], 'do'),\n",
       " (['do', 'will', 'company'], '.'),\n",
       " (['.', 'do', 'will'], 'If'),\n",
       " (['If', '.', 'do'], 'a'),\n",
       " (['a', 'If', '.'], 'lot'),\n",
       " (['lot', 'a', 'If'], 'of'),\n",
       " (['of', 'lot', 'a'], 'other'),\n",
       " (['other', 'of', 'lot'], 'people'),\n",
       " (['people', 'other', 'of'], 'make'),\n",
       " (['make', 'people', 'other'], 'the'),\n",
       " (['the', 'make', 'people'], 'same'),\n",
       " (['same', 'the', 'make'], 'prediction'),\n",
       " (['prediction', 'same', 'the'], ','),\n",
       " ([',', 'prediction', 'same'], 'the'),\n",
       " (['the', ',', 'prediction'], 'stock'),\n",
       " (['stock', 'the', ','], 'price'),\n",
       " (['price', 'stock', 'the'], 'will'),\n",
       " (['will', 'price', 'stock'], 'already'),\n",
       " (['already', 'will', 'price'], 'reflect'),\n",
       " (['reflect', 'already', 'will'], 'it'),\n",
       " (['it', 'reflect', 'already'], ','),\n",
       " ([',', 'it', 'reflect'], 'and'),\n",
       " (['and', ',', 'it'], 'there'),\n",
       " (['there', 'and', ','], 's'),\n",
       " (['s', 'there', 'and'], 'no'),\n",
       " (['no', 's', 'there'], 'room'),\n",
       " (['room', 'no', 's'], 'to'),\n",
       " (['to', 'room', 'no'], 'make'),\n",
       " (['make', 'to', 'room'], 'money'),\n",
       " (['money', 'make', 'to'], '.'),\n",
       " (['.', 'money', 'make'], 'The'),\n",
       " (['The', '.', 'money'], 'only'),\n",
       " (['only', 'The', '.'], 'valuable'),\n",
       " (['valuable', 'only', 'The'], 'insights'),\n",
       " (['insights', 'valuable', 'only'], 'are'),\n",
       " (['are', 'insights', 'valuable'], 'the'),\n",
       " (['the', 'are', 'insights'], 'ones'),\n",
       " (['ones', 'the', 'are'], 'most'),\n",
       " (['most', 'ones', 'the'], 'other'),\n",
       " (['other', 'most', 'ones'], 'investors'),\n",
       " (['investors', 'other', 'most'], 'do'),\n",
       " (['do', 'investors', 'other'], 'nt'),\n",
       " (['nt', 'do', 'investors'], 'share'),\n",
       " (['share', 'nt', 'do'], '.'),\n",
       " (['.', 'share', 'nt'], 'You'),\n",
       " (['You', '.', 'share'], 'see'),\n",
       " (['see', 'You', '.'], 'this'),\n",
       " (['this', 'see', 'You'], 'pattern'),\n",
       " (['pattern', 'this', 'see'], 'with'),\n",
       " (['with', 'pattern', 'this'], 'startup'),\n",
       " (['startup', 'with', 'pattern'], 'founders'),\n",
       " (['founders', 'startup', 'with'], 'too'),\n",
       " (['too', 'founders', 'startup'], '.'),\n",
       " (['.', 'too', 'founders'], 'You'),\n",
       " (['You', '.', 'too'], 'do'),\n",
       " (['do', 'You', '.'], 'nt'),\n",
       " (['nt', 'do', 'You'], 'want'),\n",
       " (['want', 'nt', 'do'], 'to'),\n",
       " (['to', 'want', 'nt'], 'start'),\n",
       " (['start', 'to', 'want'], 'a'),\n",
       " (['a', 'start', 'to'], 'startup'),\n",
       " (['startup', 'a', 'start'], 'to'),\n",
       " (['to', 'startup', 'a'], 'do'),\n",
       " (['do', 'to', 'startup'], 'something'),\n",
       " (['something', 'do', 'to'], 'that'),\n",
       " (['that', 'something', 'do'], 'everyone'),\n",
       " (['everyone', 'that', 'something'], 'agrees'),\n",
       " (['agrees', 'everyone', 'that'], 'is'),\n",
       " (['is', 'agrees', 'everyone'], 'a'),\n",
       " (['a', 'is', 'agrees'], 'good'),\n",
       " (['good', 'a', 'is'], 'idea'),\n",
       " (['idea', 'good', 'a'], ','),\n",
       " ([',', 'idea', 'good'], 'or'),\n",
       " (['or', ',', 'idea'], 'there'),\n",
       " (['there', 'or', ','], 'will'),\n",
       " (['will', 'there', 'or'], 'already'),\n",
       " (['already', 'will', 'there'], 'be'),\n",
       " (['be', 'already', 'will'], 'other'),\n",
       " (['other', 'be', 'already'], 'companies'),\n",
       " (['companies', 'other', 'be'], 'doing'),\n",
       " (['doing', 'companies', 'other'], 'it'),\n",
       " (['it', 'doing', 'companies'], '.'),\n",
       " (['.', 'it', 'doing'], 'You'),\n",
       " (['You', '.', 'it'], 'have'),\n",
       " (['have', 'You', '.'], 'to'),\n",
       " (['to', 'have', 'You'], 'do'),\n",
       " (['do', 'to', 'have'], 'something'),\n",
       " (['something', 'do', 'to'], 'that'),\n",
       " (['that', 'something', 'do'], 'sounds'),\n",
       " (['sounds', 'that', 'something'], 'to'),\n",
       " (['to', 'sounds', 'that'], 'most'),\n",
       " (['most', 'to', 'sounds'], 'other'),\n",
       " (['other', 'most', 'to'], 'people'),\n",
       " (['people', 'other', 'most'], 'like'),\n",
       " (['like', 'people', 'other'], 'a'),\n",
       " (['a', 'like', 'people'], 'bad'),\n",
       " (['bad', 'a', 'like'], 'idea'),\n",
       " (['idea', 'bad', 'a'], ','),\n",
       " ([',', 'idea', 'bad'], 'but'),\n",
       " (['but', ',', 'idea'], 'that'),\n",
       " (['that', 'but', ','], 'you'),\n",
       " (['you', 'that', 'but'], 'know'),\n",
       " (['know', 'you', 'that'], 'is'),\n",
       " (['is', 'know', 'you'], 'nt'),\n",
       " (['nt', 'is', 'know'], '\\x97'),\n",
       " (['\\x97', 'nt', 'is'], 'like'),\n",
       " (['like', '\\x97', 'nt'], 'writing'),\n",
       " (['writing', 'like', '\\x97'], 'software'),\n",
       " (['software', 'writing', 'like'], 'for'),\n",
       " (['for', 'software', 'writing'], 'a'),\n",
       " (['a', 'for', 'software'], 'tiny'),\n",
       " (['tiny', 'a', 'for'], 'computer'),\n",
       " (['computer', 'tiny', 'a'], 'used'),\n",
       " (['used', 'computer', 'tiny'], 'by'),\n",
       " (['by', 'used', 'computer'], 'a'),\n",
       " (['a', 'by', 'used'], 'few'),\n",
       " (['few', 'a', 'by'], 'thousand'),\n",
       " (['thousand', 'few', 'a'], 'hobbyists'),\n",
       " (['hobbyists', 'thousand', 'few'], ','),\n",
       " ([',', 'hobbyists', 'thousand'], 'or'),\n",
       " (['or', ',', 'hobbyists'], 'starting'),\n",
       " (['starting', 'or', ','], 'a'),\n",
       " (['a', 'starting', 'or'], 'site'),\n",
       " (['site', 'a', 'starting'], 'to'),\n",
       " (['to', 'site', 'a'], 'let'),\n",
       " (['let', 'to', 'site'], 'people'),\n",
       " (['people', 'let', 'to'], 'rent'),\n",
       " (['rent', 'people', 'let'], 'airbeds'),\n",
       " (['airbeds', 'rent', 'people'], 'on'),\n",
       " (['on', 'airbeds', 'rent'], 'strangers'),\n",
       " (['strangers', 'on', 'airbeds'], 'floors'),\n",
       " (['floors', 'strangers', 'on'], '.'),\n",
       " (['.', 'floors', 'strangers'], 'Ditto'),\n",
       " (['Ditto', '.', 'floors'], 'for'),\n",
       " (['for', 'Ditto', '.'], 'essayists'),\n",
       " (['essayists', 'for', 'Ditto'], '.'),\n",
       " (['.', 'essayists', 'for'], 'An'),\n",
       " (['An', '.', 'essayists'], 'essay'),\n",
       " (['essay', 'An', '.'], 'that'),\n",
       " (['that', 'essay', 'An'], 'told'),\n",
       " (['told', 'that', 'essay'], 'people'),\n",
       " (['people', 'told', 'that'], 'things'),\n",
       " (['things', 'people', 'told'], 'they'),\n",
       " (['they', 'things', 'people'], 'already'),\n",
       " (['already', 'they', 'things'], 'knew'),\n",
       " (['knew', 'already', 'they'], 'would'),\n",
       " (['would', 'knew', 'already'], 'be'),\n",
       " (['be', 'would', 'knew'], 'boring'),\n",
       " (['boring', 'be', 'would'], '.'),\n",
       " (['.', 'boring', 'be'], 'You'),\n",
       " (['You', '.', 'boring'], 'have'),\n",
       " (['have', 'You', '.'], 'to'),\n",
       " (['to', 'have', 'You'], 'tell'),\n",
       " (['tell', 'to', 'have'], 'them'),\n",
       " (['them', 'tell', 'to'], 'something'),\n",
       " (['something', 'them', 'tell'], 'new'),\n",
       " (['new', 'something', 'them'], '.'),\n",
       " (['.', 'new', 'something'], 'But'),\n",
       " (['But', '.', 'new'], 'this'),\n",
       " (['this', 'But', '.'], 'pattern'),\n",
       " (['pattern', 'this', 'But'], 'is'),\n",
       " (['is', 'pattern', 'this'], 'nt'),\n",
       " (['nt', 'is', 'pattern'], 'universal'),\n",
       " (['universal', 'nt', 'is'], '.'),\n",
       " (['.', 'universal', 'nt'], 'In'),\n",
       " (['In', '.', 'universal'], 'fact'),\n",
       " (['fact', 'In', '.'], ','),\n",
       " ([',', 'fact', 'In'], 'it'),\n",
       " (['it', ',', 'fact'], 'does'),\n",
       " (['does', 'it', ','], 'nt'),\n",
       " (['nt', 'does', 'it'], 'hold'),\n",
       " (['hold', 'nt', 'does'], 'for'),\n",
       " (['for', 'hold', 'nt'], 'most'),\n",
       " (['most', 'for', 'hold'], 'kinds'),\n",
       " (['kinds', 'most', 'for'], 'of'),\n",
       " (['of', 'kinds', 'most'], 'work'),\n",
       " (['work', 'of', 'kinds'], '.'),\n",
       " (['.', 'work', 'of'], 'In'),\n",
       " (['In', '.', 'work'], 'most'),\n",
       " (['most', 'In', '.'], 'kinds'),\n",
       " (['kinds', 'most', 'In'], 'of'),\n",
       " (['of', 'kinds', 'most'], 'work'),\n",
       " (['work', 'of', 'kinds'], '\\x97'),\n",
       " (['\\x97', 'work', 'of'], 'to'),\n",
       " (['to', '\\x97', 'work'], 'be'),\n",
       " (['be', 'to', '\\x97'], 'an'),\n",
       " (['an', 'be', 'to'], 'administrator'),\n",
       " (['administrator', 'an', 'be'], ','),\n",
       " ([',', 'administrator', 'an'], 'for'),\n",
       " (['for', ',', 'administrator'], 'example'),\n",
       " (['example', 'for', ','], '\\x97'),\n",
       " (['\\x97', 'example', 'for'], 'all'),\n",
       " (['all', '\\x97', 'example'], 'you'),\n",
       " (['you', 'all', '\\x97'], 'need'),\n",
       " (['need', 'you', 'all'], 'is'),\n",
       " (['is', 'need', 'you'], 'the'),\n",
       " (['the', 'is', 'need'], 'first'),\n",
       " (['first', 'the', 'is'], 'half'),\n",
       " (['half', 'first', 'the'], '.'),\n",
       " (['.', 'half', 'first'], 'All'),\n",
       " (['All', '.', 'half'], 'you'),\n",
       " (['you', 'All', '.'], 'need'),\n",
       " (['need', 'you', 'All'], 'is'),\n",
       " (['is', 'need', 'you'], 'to'),\n",
       " (['to', 'is', 'need'], 'be'),\n",
       " (['be', 'to', 'is'], 'right'),\n",
       " (['right', 'be', 'to'], '.'),\n",
       " (['.', 'right', 'be'], 'Its'),\n",
       " (['Its', '.', 'right'], 'not'),\n",
       " (['not', 'Its', '.'], 'essential'),\n",
       " (['essential', 'not', 'Its'], 'that'),\n",
       " (['that', 'essential', 'not'], 'everyone'),\n",
       " (['everyone', 'that', 'essential'], 'else'),\n",
       " (['else', 'everyone', 'that'], 'be'),\n",
       " (['be', 'else', 'everyone'], 'wrong'),\n",
       " (['wrong', 'be', 'else'], '.'),\n",
       " (['.', 'wrong', 'be'], 'Theres'),\n",
       " (['Theres', '.', 'wrong'], 'room'),\n",
       " (['room', 'Theres', '.'], 'for'),\n",
       " (['for', 'room', 'Theres'], 'a'),\n",
       " (['a', 'for', 'room'], 'little'),\n",
       " (['little', 'a', 'for'], 'novelty'),\n",
       " (['novelty', 'little', 'a'], 'in'),\n",
       " (['in', 'novelty', 'little'], 'most'),\n",
       " (['most', 'in', 'novelty'], 'kinds'),\n",
       " (['kinds', 'most', 'in'], 'of'),\n",
       " (['of', 'kinds', 'most'], 'work'),\n",
       " (['work', 'of', 'kinds'], ','),\n",
       " ([',', 'work', 'of'], 'but'),\n",
       " (['but', ',', 'work'], 'in'),\n",
       " (['in', 'but', ','], 'practice'),\n",
       " (['practice', 'in', 'but'], 'there'),\n",
       " (['there', 'practice', 'in'], 's'),\n",
       " (['s', 'there', 'practice'], 'a'),\n",
       " (['a', 's', 'there'], 'fairly'),\n",
       " (['fairly', 'a', 's'], 'sharp'),\n",
       " (['sharp', 'fairly', 'a'], 'distinction'),\n",
       " (['distinction', 'sharp', 'fairly'], 'between'),\n",
       " (['between', 'distinction', 'sharp'], 'the'),\n",
       " (['the', 'between', 'distinction'], 'kinds'),\n",
       " (['kinds', 'the', 'between'], 'of'),\n",
       " (['of', 'kinds', 'the'], 'work'),\n",
       " (['work', 'of', 'kinds'], 'where'),\n",
       " (['where', 'work', 'of'], 'its'),\n",
       " (['its', 'where', 'work'], 'essential'),\n",
       " (['essential', 'its', 'where'], 'to'),\n",
       " (['to', 'essential', 'its'], 'be'),\n",
       " (['be', 'to', 'essential'], 'independent'),\n",
       " (['independent', 'be', 'to'], '-'),\n",
       " (['-', 'independent', 'be'], 'minded'),\n",
       " (['minded', '-', 'independent'], ','),\n",
       " ([',', 'minded', '-'], 'and'),\n",
       " (['and', ',', 'minded'], 'the'),\n",
       " (['the', 'and', ','], 'kinds'),\n",
       " (['kinds', 'the', 'and'], 'where'),\n",
       " (['where', 'kinds', 'the'], 'its'),\n",
       " (['its', 'where', 'kinds'], 'not'),\n",
       " (['not', 'its', 'where'], '.'),\n",
       " (['.', 'not', 'its'], 'I'),\n",
       " (['I', '.', 'not'], 'wish'),\n",
       " (['wish', 'I', '.'], 'someone'),\n",
       " (['someone', 'wish', 'I'], 'had'),\n",
       " (['had', 'someone', 'wish'], 'told'),\n",
       " (['told', 'had', 'someone'], 'me'),\n",
       " (['me', 'told', 'had'], 'about'),\n",
       " (['about', 'me', 'told'], 'this'),\n",
       " (['this', 'about', 'me'], 'distinction'),\n",
       " (['distinction', 'this', 'about'], 'when'),\n",
       " (['when', 'distinction', 'this'], 'I'),\n",
       " (['I', 'when', 'distinction'], 'was'),\n",
       " (['was', 'I', 'when'], 'a'),\n",
       " (['a', 'was', 'I'], 'kid'),\n",
       " (['kid', 'a', 'was'], ','),\n",
       " ([',', 'kid', 'a'], 'because'),\n",
       " (['because', ',', 'kid'], 'its'),\n",
       " (['its', 'because', ','], 'one'),\n",
       " (['one', 'its', 'because'], 'of'),\n",
       " (['of', 'one', 'its'], 'the'),\n",
       " (['the', 'of', 'one'], 'most'),\n",
       " (['most', 'the', 'of'], 'important'),\n",
       " (['important', 'most', 'the'], 'things'),\n",
       " (['things', 'important', 'most'], 'to'),\n",
       " (['to', 'things', 'important'], 'think'),\n",
       " (['think', 'to', 'things'], 'about'),\n",
       " (['about', 'think', 'to'], 'when'),\n",
       " (['when', 'about', 'think'], 'you'),\n",
       " (['you', 'when', 'about'], 're'),\n",
       " (['re', 'you', 'when'], 'deciding'),\n",
       " (['deciding', 're', 'you'], 'what'),\n",
       " (['what', 'deciding', 're'], 'kind'),\n",
       " (['kind', 'what', 'deciding'], 'of'),\n",
       " (['of', 'kind', 'what'], 'work'),\n",
       " (['work', 'of', 'kind'], 'you'),\n",
       " (['you', 'work', 'of'], 'want'),\n",
       " (['want', 'you', 'work'], 'to'),\n",
       " (['to', 'want', 'you'], 'do'),\n",
       " (['do', 'to', 'want'], '.'),\n",
       " (['.', 'do', 'to'], 'Do'),\n",
       " (['Do', '.', 'do'], 'you'),\n",
       " (['you', 'Do', '.'], 'want'),\n",
       " (['want', 'you', 'Do'], 'to'),\n",
       " (['to', 'want', 'you'], 'do'),\n",
       " (['do', 'to', 'want'], 'the'),\n",
       " (['the', 'do', 'to'], 'kind'),\n",
       " (['kind', 'the', 'do'], 'of'),\n",
       " (['of', 'kind', 'the'], 'work'),\n",
       " (['work', 'of', 'kind'], 'where'),\n",
       " (['where', 'work', 'of'], 'you'),\n",
       " (['you', 'where', 'work'], 'can'),\n",
       " (['can', 'you', 'where'], 'only'),\n",
       " (['only', 'can', 'you'], 'win'),\n",
       " (['win', 'only', 'can'], 'by'),\n",
       " (['by', 'win', 'only'], 'thinking'),\n",
       " (['thinking', 'by', 'win'], 'differently'),\n",
       " (['differently', 'thinking', 'by'], 'from'),\n",
       " (['from', 'differently', 'thinking'], 'everyone'),\n",
       " (['everyone', 'from', 'differently'], 'else'),\n",
       " (['else', 'everyone', 'from'], '?'),\n",
       " (['?', 'else', 'everyone'], 'I'),\n",
       " (['I', '?', 'else'], 'suspect'),\n",
       " (['suspect', 'I', '?'], 'most'),\n",
       " (['most', 'suspect', 'I'], 'peoples'),\n",
       " (['peoples', 'most', 'suspect'], 'unconscious'),\n",
       " (['unconscious', 'peoples', 'most'], 'mind'),\n",
       " (['mind', 'unconscious', 'peoples'], 'will'),\n",
       " (['will', 'mind', 'unconscious'], 'answer'),\n",
       " (['answer', 'will', 'mind'], 'that'),\n",
       " (['that', 'answer', 'will'], 'question'),\n",
       " (['question', 'that', 'answer'], 'before'),\n",
       " (['before', 'question', 'that'], 'their'),\n",
       " (['their', 'before', 'question'], 'conscious'),\n",
       " (['conscious', 'their', 'before'], 'mind'),\n",
       " (['mind', 'conscious', 'their'], 'has'),\n",
       " (['has', 'mind', 'conscious'], 'a'),\n",
       " (['a', 'has', 'mind'], 'chance'),\n",
       " (['chance', 'a', 'has'], 'to'),\n",
       " (['to', 'chance', 'a'], '.'),\n",
       " (['.', 'to', 'chance'], 'I'),\n",
       " (['I', '.', 'to'], 'know'),\n",
       " (['know', 'I', '.'], 'mine'),\n",
       " (['mine', 'know', 'I'], 'does'),\n",
       " (['does', 'mine', 'know'], '.'),\n",
       " (['.', 'does', 'mine'], 'Independent'),\n",
       " (['Independent', '.', 'does'], '-'),\n",
       " (['-', 'Independent', '.'], 'mindedness'),\n",
       " (['mindedness', '-', 'Independent'], 'seems'),\n",
       " (['seems', 'mindedness', '-'], 'to'),\n",
       " (['to', 'seems', 'mindedness'], 'be'),\n",
       " (['be', 'to', 'seems'], 'more'),\n",
       " (['more', 'be', 'to'], 'a'),\n",
       " (['a', 'more', 'be'], 'matter'),\n",
       " (['matter', 'a', 'more'], 'of'),\n",
       " (['of', 'matter', 'a'], 'nature'),\n",
       " (['nature', 'of', 'matter'], 'than'),\n",
       " (['than', 'nature', 'of'], 'nurture'),\n",
       " (['nurture', 'than', 'nature'], '.'),\n",
       " (['.', 'nurture', 'than'], 'Which'),\n",
       " (['Which', '.', 'nurture'], 'means'),\n",
       " (['means', 'Which', '.'], 'if'),\n",
       " (['if', 'means', 'Which'], 'you'),\n",
       " (['you', 'if', 'means'], 'pick'),\n",
       " (['pick', 'you', 'if'], 'the'),\n",
       " (['the', 'pick', 'you'], 'wrong'),\n",
       " (['wrong', 'the', 'pick'], 'type'),\n",
       " (['type', 'wrong', 'the'], 'of'),\n",
       " (['of', 'type', 'wrong'], 'work'),\n",
       " (['work', 'of', 'type'], ','),\n",
       " ([',', 'work', 'of'], 'you'),\n",
       " (['you', ',', 'work'], 're'),\n",
       " (['re', 'you', ','], 'going'),\n",
       " (['going', 're', 'you'], 'to'),\n",
       " (['to', 'going', 're'], 'be'),\n",
       " (['be', 'to', 'going'], 'unhappy'),\n",
       " (['unhappy', 'be', 'to'], '.'),\n",
       " (['.', 'unhappy', 'be'], 'If'),\n",
       " (['If', '.', 'unhappy'], 'you'),\n",
       " (['you', 'If', '.'], 're'),\n",
       " (['re', 'you', 'If'], 'naturally'),\n",
       " (['naturally', 're', 'you'], 'independent'),\n",
       " (['independent', 'naturally', 're'], '-'),\n",
       " (['-', 'independent', 'naturally'], 'minded'),\n",
       " (['minded', '-', 'independent'], ','),\n",
       " ([',', 'minded', '-'], 'you'),\n",
       " (['you', ',', 'minded'], 're'),\n",
       " (['re', 'you', ','], 'going'),\n",
       " (['going', 're', 'you'], 'to'),\n",
       " (['to', 'going', 're'], 'find'),\n",
       " (['find', 'to', 'going'], 'it'),\n",
       " (['it', 'find', 'to'], 'frustrating'),\n",
       " (['frustrating', 'it', 'find'], 'to'),\n",
       " (['to', 'frustrating', 'it'], 'be'),\n",
       " (['be', 'to', 'frustrating'], 'a'),\n",
       " (['a', 'be', 'to'], 'middle'),\n",
       " (['middle', 'a', 'be'], 'manager'),\n",
       " (['manager', 'middle', 'a'], '.'),\n",
       " (['.', 'manager', 'middle'], 'And'),\n",
       " (['And', '.', 'manager'], 'if'),\n",
       " (['if', 'And', '.'], 'you'),\n",
       " (['you', 'if', 'And'], 're'),\n",
       " (['re', 'you', 'if'], 'naturally'),\n",
       " (['naturally', 're', 'you'], 'conventional'),\n",
       " (['conventional', 'naturally', 're'], '-'),\n",
       " (['-', 'conventional', 'naturally'], 'minded'),\n",
       " (['minded', '-', 'conventional'], ','),\n",
       " ([',', 'minded', '-'], 'you'),\n",
       " (['you', ',', 'minded'], 're'),\n",
       " (['re', 'you', ','], 'going'),\n",
       " (['going', 're', 'you'], 'to'),\n",
       " (['to', 'going', 're'], 'be'),\n",
       " (['be', 'to', 'going'], 'sailing'),\n",
       " (['sailing', 'be', 'to'], 'into'),\n",
       " (['into', 'sailing', 'be'], 'a'),\n",
       " (['a', 'into', 'sailing'], 'headwind'),\n",
       " (['headwind', 'a', 'into'], 'if'),\n",
       " (['if', 'headwind', 'a'], 'you'),\n",
       " (['you', 'if', 'headwind'], 'try'),\n",
       " (['try', 'you', 'if'], 'to'),\n",
       " (['to', 'try', 'you'], 'do'),\n",
       " (['do', 'to', 'try'], 'original'),\n",
       " (['original', 'do', 'to'], 'research'),\n",
       " (['research', 'original', 'do'], '.'),\n",
       " (['.', 'research', 'original'], 'One'),\n",
       " (['One', '.', 'research'], 'difficulty'),\n",
       " (['difficulty', 'One', '.'], 'here'),\n",
       " (['here', 'difficulty', 'One'], ','),\n",
       " ([',', 'here', 'difficulty'], 'though'),\n",
       " (['though', ',', 'here'], ','),\n",
       " ([',', 'though', ','], 'is'),\n",
       " (['is', ',', 'though'], 'that'),\n",
       " (['that', 'is', ','], 'people'),\n",
       " (['people', 'that', 'is'], 'are'),\n",
       " (['are', 'people', 'that'], 'often'),\n",
       " (['often', 'are', 'people'], 'mistaken'),\n",
       " (['mistaken', 'often', 'are'], 'about'),\n",
       " (['about', 'mistaken', 'often'], 'where'),\n",
       " (['where', 'about', 'mistaken'], 'they'),\n",
       " (['they', 'where', 'about'], 'fall'),\n",
       " (['fall', 'they', 'where'], 'on'),\n",
       " (['on', 'fall', 'they'], 'the'),\n",
       " (['the', 'on', 'fall'], 'spectrum'),\n",
       " (['spectrum', 'the', 'on'], 'from'),\n",
       " (['from', 'spectrum', 'the'], 'conventional-'),\n",
       " (['conventional-', 'from', 'spectrum'], 'to'),\n",
       " (['to', 'conventional-', 'from'], 'independent'),\n",
       " (['independent', 'to', 'conventional-'], '-'),\n",
       " (['-', 'independent', 'to'], 'minded'),\n",
       " (['minded', '-', 'independent'], '.'),\n",
       " (['.', 'minded', '-'], 'Conventional'),\n",
       " (['Conventional', '.', 'minded'], '-'),\n",
       " (['-', 'Conventional', '.'], 'minded'),\n",
       " (['minded', '-', 'Conventional'], 'people'),\n",
       " (['people', 'minded', '-'], 'do'),\n",
       " (['do', 'people', 'minded'], 'nt'),\n",
       " (['nt', 'do', 'people'], 'like'),\n",
       " (['like', 'nt', 'do'], 'to'),\n",
       " (['to', 'like', 'nt'], 'think'),\n",
       " (['think', 'to', 'like'], 'of'),\n",
       " (['of', 'think', 'to'], 'themselves'),\n",
       " (['themselves', 'of', 'think'], 'as'),\n",
       " (['as', 'themselves', 'of'], 'conventional'),\n",
       " (['conventional', 'as', 'themselves'], '-'),\n",
       " (['-', 'conventional', 'as'], 'minded'),\n",
       " (['minded', '-', 'conventional'], '.'),\n",
       " (['.', 'minded', '-'], 'And'),\n",
       " (['And', '.', 'minded'], 'in'),\n",
       " (['in', 'And', '.'], 'any'),\n",
       " (['any', 'in', 'And'], 'case'),\n",
       " (['case', 'any', 'in'], ','),\n",
       " ([',', 'case', 'any'], 'it'),\n",
       " (['it', ',', 'case'], 'genuinely'),\n",
       " (['genuinely', 'it', ','], 'feels'),\n",
       " (['feels', 'genuinely', 'it'], 'to'),\n",
       " (['to', 'feels', 'genuinely'], 'them'),\n",
       " (['them', 'to', 'feels'], 'as'),\n",
       " (['as', 'them', 'to'], 'if'),\n",
       " (['if', 'as', 'them'], 'they'),\n",
       " (['they', 'if', 'as'], 'make'),\n",
       " (['make', 'they', 'if'], 'up'),\n",
       " (['up', 'make', 'they'], 'their'),\n",
       " (['their', 'up', 'make'], 'own'),\n",
       " (['own', 'their', 'up'], 'minds'),\n",
       " (['minds', 'own', 'their'], 'about'),\n",
       " (['about', 'minds', 'own'], 'everything'),\n",
       " (['everything', 'about', 'minds'], '.'),\n",
       " (['.', 'everything', 'about'], 'Its'),\n",
       " (['Its', '.', 'everything'], 'just'),\n",
       " (['just', 'Its', '.'], 'a'),\n",
       " (['a', 'just', 'Its'], 'coincidence'),\n",
       " (['coincidence', 'a', 'just'], 'that'),\n",
       " (['that', 'coincidence', 'a'], 'their'),\n",
       " (['their', 'that', 'coincidence'], 'beliefs'),\n",
       " (['beliefs', 'their', 'that'], 'are'),\n",
       " (['are', 'beliefs', 'their'], 'identical'),\n",
       " (['identical', 'are', 'beliefs'], 'to'),\n",
       " (['to', 'identical', 'are'], 'their'),\n",
       " (['their', 'to', 'identical'], 'peers'),\n",
       " (['peers', 'their', 'to'], '.'),\n",
       " (['.', 'peers', 'their'], 'And'),\n",
       " (['And', '.', 'peers'], 'the'),\n",
       " (['the', 'And', '.'], 'independent'),\n",
       " (['independent', 'the', 'And'], '-'),\n",
       " (['-', 'independent', 'the'], 'minded'),\n",
       " (['minded', '-', 'independent'], ','),\n",
       " ([',', 'minded', '-'], 'meanwhile'),\n",
       " (['meanwhile', ',', 'minded'], ','),\n",
       " ([',', 'meanwhile', ','], 'are'),\n",
       " (['are', ',', 'meanwhile'], 'often'),\n",
       " (['often', 'are', ','], 'unaware'),\n",
       " (['unaware', 'often', 'are'], 'how'),\n",
       " (['how', 'unaware', 'often'], 'different'),\n",
       " (['different', 'how', 'unaware'], 'their'),\n",
       " (['their', 'different', 'how'], 'ideas'),\n",
       " (['ideas', 'their', 'different'], 'are'),\n",
       " (['are', 'ideas', 'their'], 'from'),\n",
       " (['from', 'are', 'ideas'], 'conventional'),\n",
       " (['conventional', 'from', 'are'], 'ones'),\n",
       " (['ones', 'conventional', 'from'], ','),\n",
       " ([',', 'ones', 'conventional'], 'at'),\n",
       " (['at', ',', 'ones'], 'least'),\n",
       " (['least', 'at', ','], 'till'),\n",
       " (['till', 'least', 'at'], 'they'),\n",
       " (['they', 'till', 'least'], 'state'),\n",
       " (['state', 'they', 'till'], 'them'),\n",
       " (['them', 'state', 'they'], 'publicly'),\n",
       " (['publicly', 'them', 'state'], '.'),\n",
       " (['.', 'publicly', 'them'], '['),\n",
       " (['[', '.', 'publicly'], '1]By'),\n",
       " (['1]By', '[', '.'], 'the'),\n",
       " (['the', '1]By', '['], 'time'),\n",
       " (['time', 'the', '1]By'], 'they'),\n",
       " (['they', 'time', 'the'], 'reach'),\n",
       " (['reach', 'they', 'time'], 'adulthood'),\n",
       " (['adulthood', 'reach', 'they'], ','),\n",
       " ([',', 'adulthood', 'reach'], 'most'),\n",
       " (['most', ',', 'adulthood'], 'people'),\n",
       " (['people', 'most', ','], 'know'),\n",
       " (['know', 'people', 'most'], 'roughly'),\n",
       " (['roughly', 'know', 'people'], 'how'),\n",
       " (['how', 'roughly', 'know'], 'smart'),\n",
       " (['smart', 'how', 'roughly'], 'they'),\n",
       " (['they', 'smart', 'how'], 'are'),\n",
       " (['are', 'they', 'smart'], '('),\n",
       " (['(', 'are', 'they'], 'in'),\n",
       " (['in', '(', 'are'], 'the'),\n",
       " (['the', 'in', '('], 'narrow'),\n",
       " (['narrow', 'the', 'in'], 'sense'),\n",
       " (['sense', 'narrow', 'the'], 'of'),\n",
       " (['of', 'sense', 'narrow'], 'ability'),\n",
       " (['ability', 'of', 'sense'], 'to'),\n",
       " (['to', 'ability', 'of'], 'solve'),\n",
       " (['solve', 'to', 'ability'], 'pre'),\n",
       " (['pre', 'solve', 'to'], '-'),\n",
       " (['-', 'pre', 'solve'], 'set'),\n",
       " (['set', '-', 'pre'], 'problems'),\n",
       " (['problems', 'set', '-'], ')'),\n",
       " ([')', 'problems', 'set'], ','),\n",
       " ([',', ')', 'problems'], 'because'),\n",
       " (['because', ',', ')'], 'they'),\n",
       " (['they', 'because', ','], 're'),\n",
       " (['re', 'they', 'because'], 'constantly'),\n",
       " (['constantly', 're', 'they'], 'being'),\n",
       " (['being', 'constantly', 're'], 'tested'),\n",
       " (['tested', 'being', 'constantly'], 'and'),\n",
       " (['and', 'tested', 'being'], 'ranked'),\n",
       " (['ranked', 'and', 'tested'], 'according'),\n",
       " (['according', 'ranked', 'and'], 'to'),\n",
       " (['to', 'according', 'ranked'], 'it'),\n",
       " (['it', 'to', 'according'], '.'),\n",
       " (['.', 'it', 'to'], 'But'),\n",
       " (['But', '.', 'it'], 'schools'),\n",
       " (['schools', 'But', '.'], 'generally'),\n",
       " (['generally', 'schools', 'But'], 'ignore'),\n",
       " (['ignore', 'generally', 'schools'], 'independent'),\n",
       " (['independent', 'ignore', 'generally'], '-'),\n",
       " (['-', 'independent', 'ignore'], 'mindedness'),\n",
       " (['mindedness', '-', 'independent'], ','),\n",
       " ([',', 'mindedness', '-'], 'except'),\n",
       " (['except', ',', 'mindedness'], 'to'),\n",
       " (['to', 'except', ','], 'the'),\n",
       " (['the', 'to', 'except'], 'extent'),\n",
       " (['extent', 'the', 'to'], 'they'),\n",
       " (['they', 'extent', 'the'], 'try'),\n",
       " (['try', 'they', 'extent'], 'to'),\n",
       " (['to', 'try', 'they'], 'suppress'),\n",
       " (['suppress', 'to', 'try'], 'it'),\n",
       " (['it', 'suppress', 'to'], '.'),\n",
       " (['.', 'it', 'suppress'], 'So'),\n",
       " (['So', '.', 'it'], 'we'),\n",
       " (['we', 'So', '.'], 'do'),\n",
       " (['do', 'we', 'So'], 'nt'),\n",
       " (['nt', 'do', 'we'], 'get'),\n",
       " (['get', 'nt', 'do'], 'anything'),\n",
       " (['anything', 'get', 'nt'], 'like'),\n",
       " (['like', 'anything', 'get'], 'the'),\n",
       " (['the', 'like', 'anything'], 'same'),\n",
       " (['same', 'the', 'like'], 'kind'),\n",
       " (['kind', 'same', 'the'], 'of'),\n",
       " (['of', 'kind', 'same'], 'feedback'),\n",
       " (['feedback', 'of', 'kind'], 'about'),\n",
       " (['about', 'feedback', 'of'], 'how'),\n",
       " (['how', 'about', 'feedback'], 'independent'),\n",
       " (['independent', 'how', 'about'], '-'),\n",
       " (['-', 'independent', 'how'], 'minded'),\n",
       " (['minded', '-', 'independent'], 'we'),\n",
       " (['we', 'minded', '-'], 'are'),\n",
       " (['are', 'we', 'minded'], '.'),\n",
       " (['.', 'are', 'we'], 'There'),\n",
       " (['There', '.', 'are'], 'may'),\n",
       " (['may', 'There', '.'], 'even'),\n",
       " (['even', 'may', 'There'], 'be'),\n",
       " (['be', 'even', 'may'], 'a'),\n",
       " (['a', 'be', 'even'], 'phenomenon'),\n",
       " (['phenomenon', 'a', 'be'], 'like'),\n",
       " (['like', 'phenomenon', 'a'], 'Dunning'),\n",
       " (['Dunning', 'like', 'phenomenon'], '-'),\n",
       " (['-', 'Dunning', 'like'], 'Kruger'),\n",
       " (['Kruger', '-', 'Dunning'], 'at'),\n",
       " (['at', 'Kruger', '-'], 'work'),\n",
       " (['work', 'at', 'Kruger'], ','),\n",
       " ([',', 'work', 'at'], 'where'),\n",
       " (['where', ',', 'work'], 'the'),\n",
       " (['the', 'where', ','], 'most'),\n",
       " (['most', 'the', 'where'], 'conventional'),\n",
       " (['conventional', 'most', 'the'], '-'),\n",
       " (['-', 'conventional', 'most'], 'minded'),\n",
       " (['minded', '-', 'conventional'], 'people'),\n",
       " (['people', 'minded', '-'], 'are'),\n",
       " (['are', 'people', 'minded'], 'confident'),\n",
       " (['confident', 'are', 'people'], 'that'),\n",
       " (['that', 'confident', 'are'], 'they'),\n",
       " (['they', 'that', 'confident'], 're'),\n",
       " (['re', 'they', 'that'], 'independent'),\n",
       " (['independent', 're', 'they'], '-'),\n",
       " (['-', 'independent', 're'], 'minded'),\n",
       " (['minded', '-', 'independent'], ','),\n",
       " ([',', 'minded', '-'], 'while'),\n",
       " (['while', ',', 'minded'], 'the'),\n",
       " (['the', 'while', ','], 'genuinely'),\n",
       " (['genuinely', 'the', 'while'], 'independent'),\n",
       " (['independent', 'genuinely', 'the'], '-'),\n",
       " (['-', 'independent', 'genuinely'], 'minded'),\n",
       " (['minded', '-', 'independent'], 'worry'),\n",
       " (['worry', 'minded', '-'], 'they'),\n",
       " (['they', 'worry', 'minded'], 'might'),\n",
       " (['might', 'they', 'worry'], 'not'),\n",
       " (['not', 'might', 'they'], 'be'),\n",
       " (['be', 'not', 'might'], 'independent'),\n",
       " (['independent', 'be', 'not'], '-'),\n",
       " (['-', 'independent', 'be'], 'minded'),\n",
       " (['minded', '-', 'independent'], 'enough'),\n",
       " (['enough', 'minded', '-'], '.'),\n",
       " (['.', 'enough', 'minded'], '_'),\n",
       " (['_', '.', 'enough'], '_'),\n",
       " (['_', '_', '.'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], '_'),\n",
       " (['_', '_', '_'], 'Can'),\n",
       " (['Can', '_', '_'], 'you'),\n",
       " (['you', 'Can', '_'], 'make'),\n",
       " (['make', 'you', 'Can'], 'yourself'),\n",
       " (['yourself', 'make', 'you'], 'more'),\n",
       " (['more', 'yourself', 'make'], 'independent'),\n",
       " (['independent', 'more', 'yourself'], '-'),\n",
       " (['-', 'independent', 'more'], 'minded'),\n",
       " (['minded', '-', 'independent'], '?'),\n",
       " (['?', 'minded', '-'], 'I'),\n",
       " (['I', '?', 'minded'], 'think'),\n",
       " (['think', 'I', '?'], 'so'),\n",
       " (['so', 'think', 'I'], '.'),\n",
       " (['.', 'so', 'think'], 'This'),\n",
       " (['This', '.', 'so'], 'quality'),\n",
       " (['quality', 'This', '.'], 'may'),\n",
       " (['may', 'quality', 'This'], 'be'),\n",
       " (['be', 'may', 'quality'], 'largely'),\n",
       " (['largely', 'be', 'may'], 'inborn'),\n",
       " (['inborn', 'largely', 'be'], ','),\n",
       " ([',', 'inborn', 'largely'], 'but'),\n",
       " (['but', ',', 'inborn'], 'there'),\n",
       " (['there', 'but', ','], 'seem'),\n",
       " (['seem', 'there', 'but'], 'to'),\n",
       " (['to', 'seem', 'there'], 'be'),\n",
       " (['be', 'to', 'seem'], 'ways'),\n",
       " (['ways', 'be', 'to'], 'to'),\n",
       " (['to', 'ways', 'be'], 'magnify'),\n",
       " (['magnify', 'to', 'ways'], 'it'),\n",
       " (['it', 'magnify', 'to'], ','),\n",
       " ([',', 'it', 'magnify'], 'or'),\n",
       " (['or', ',', 'it'], 'at'),\n",
       " (['at', 'or', ','], 'least'),\n",
       " (['least', 'at', 'or'], 'not'),\n",
       " (['not', 'least', 'at'], 'to'),\n",
       " (['to', 'not', 'least'], 'suppress'),\n",
       " (['suppress', 'to', 'not'], 'it'),\n",
       " (['it', 'suppress', 'to'], '.'),\n",
       " (['.', 'it', 'suppress'], 'One'),\n",
       " (['One', '.', 'it'], 'of'),\n",
       " (['of', 'One', '.'], 'the'),\n",
       " (['the', 'of', 'One'], 'most'),\n",
       " (['most', 'the', 'of'], 'effective'),\n",
       " (['effective', 'most', 'the'], 'techniques'),\n",
       " (['techniques', 'effective', 'most'], 'is'),\n",
       " (['is', 'techniques', 'effective'], 'one'),\n",
       " (['one', 'is', 'techniques'], 'practiced'),\n",
       " (['practiced', 'one', 'is'], 'unintentionally'),\n",
       " (['unintentionally', 'practiced', 'one'], 'by'),\n",
       " (['by', 'unintentionally', 'practiced'], 'most'),\n",
       " (['most', 'by', 'unintentionally'], 'nerds'),\n",
       " (['nerds', 'most', 'by'], ':'),\n",
       " ([':', 'nerds', 'most'], 'simply'),\n",
       " (['simply', ':', 'nerds'], 'to'),\n",
       " (['to', 'simply', ':'], 'be'),\n",
       " (['be', 'to', 'simply'], 'less'),\n",
       " (['less', 'be', 'to'], 'aware'),\n",
       " (['aware', 'less', 'be'], 'what'),\n",
       " (['what', 'aware', 'less'], 'conventional'),\n",
       " (['conventional', 'what', 'aware'], 'beliefs'),\n",
       " (['beliefs', 'conventional', 'what'], 'are'),\n",
       " (['are', 'beliefs', 'conventional'], '.'),\n",
       " (['.', 'are', 'beliefs'], 'Its'),\n",
       " (['Its', '.', 'are'], 'hard'),\n",
       " (['hard', 'Its', '.'], 'to'),\n",
       " (['to', 'hard', 'Its'], 'be'),\n",
       " (['be', 'to', 'hard'], 'a'),\n",
       " (['a', 'be', 'to'], 'conformist'),\n",
       " (['conformist', 'a', 'be'], 'if'),\n",
       " (['if', 'conformist', 'a'], 'you'),\n",
       " (['you', 'if', 'conformist'], 'do'),\n",
       " (['do', 'you', 'if'], 'nt'),\n",
       " (['nt', 'do', 'you'], 'know'),\n",
       " (['know', 'nt', 'do'], 'what'),\n",
       " (['what', 'know', 'nt'], 'you'),\n",
       " (['you', 'what', 'know'], 're'),\n",
       " (['re', 'you', 'what'], 'supposed'),\n",
       " (['supposed', 're', 'you'], 'to'),\n",
       " (['to', 'supposed', 're'], 'conform'),\n",
       " (['conform', 'to', 'supposed'], 'to'),\n",
       " (['to', 'conform', 'to'], '.'),\n",
       " (['.', 'to', 'conform'], 'Though'),\n",
       " (['Though', '.', 'to'], 'again'),\n",
       " (['again', 'Though', '.'], ','),\n",
       " ([',', 'again', 'Though'], 'it'),\n",
       " (['it', ',', 'again'], 'may'),\n",
       " (['may', 'it', ','], 'be'),\n",
       " (['be', 'may', 'it'], 'that'),\n",
       " (['that', 'be', 'may'], 'such'),\n",
       " (['such', 'that', 'be'], 'people'),\n",
       " (['people', 'such', 'that'], 'already'),\n",
       " (['already', 'people', 'such'], 'are'),\n",
       " (['are', 'already', 'people'], 'independent'),\n",
       " (['independent', 'are', 'already'], '-'),\n",
       " (['-', 'independent', 'are'], 'minded'),\n",
       " (['minded', '-', 'independent'], '.'),\n",
       " (['.', 'minded', '-'], 'A'),\n",
       " (['A', '.', 'minded'], 'conventional'),\n",
       " (['conventional', 'A', '.'], '-'),\n",
       " (['-', 'conventional', 'A'], 'minded'),\n",
       " (['minded', '-', 'conventional'], 'person'),\n",
       " (['person', 'minded', '-'], 'would'),\n",
       " (['would', 'person', 'minded'], 'probably'),\n",
       " (['probably', 'would', 'person'], 'feel'),\n",
       " (['feel', 'probably', 'would'], 'anxious'),\n",
       " (['anxious', 'feel', 'probably'], 'not'),\n",
       " (['not', 'anxious', 'feel'], 'knowing'),\n",
       " (['knowing', 'not', 'anxious'], 'what'),\n",
       " (['what', 'knowing', 'not'], 'other'),\n",
       " (['other', 'what', 'knowing'], 'people'),\n",
       " (['people', 'other', 'what'], 'thought'),\n",
       " (['thought', 'people', 'other'], ','),\n",
       " ([',', 'thought', 'people'], 'and'),\n",
       " (['and', ',', 'thought'], 'make'),\n",
       " (['make', 'and', ','], 'more'),\n",
       " (['more', 'make', 'and'], 'effort'),\n",
       " (['effort', 'more', 'make'], 'to'),\n",
       " (['to', 'effort', 'more'], 'find'),\n",
       " (['find', 'to', 'effort'], 'out'),\n",
       " (['out', 'find', 'to'], '.'),\n",
       " (['.', 'out', 'find'], 'It'),\n",
       " (['It', '.', 'out'], 'matters'),\n",
       " (['matters', 'It', '.'], 'a'),\n",
       " (['a', 'matters', 'It'], 'lot'),\n",
       " (['lot', 'a', 'matters'], 'who'),\n",
       " (['who', 'lot', 'a'], 'you'),\n",
       " (['you', 'who', 'lot'], 'surround'),\n",
       " (['surround', 'you', 'who'], 'yourself'),\n",
       " (['yourself', 'surround', 'you'], 'with'),\n",
       " (['with', 'yourself', 'surround'], '.'),\n",
       " (['.', 'with', 'yourself'], 'If'),\n",
       " (['If', '.', 'with'], 'you'),\n",
       " (['you', 'If', '.'], 're'),\n",
       " (['re', 'you', 'If'], 'surrounded'),\n",
       " (['surrounded', 're', 'you'], 'by'),\n",
       " (['by', 'surrounded', 're'], 'conventional'),\n",
       " (['conventional', 'by', 'surrounded'], '-'),\n",
       " (['-', 'conventional', 'by'], 'minded'),\n",
       " (['minded', '-', 'conventional'], 'people'),\n",
       " (['people', 'minded', '-'], ','),\n",
       " ([',', 'people', 'minded'], 'it'),\n",
       " (['it', ',', 'people'], 'will'),\n",
       " (['will', 'it', ','], 'constrain'),\n",
       " (['constrain', 'will', 'it'], 'which'),\n",
       " (['which', 'constrain', 'will'], 'ideas'),\n",
       " (['ideas', 'which', 'constrain'], 'you'),\n",
       " (['you', 'ideas', 'which'], 'can'),\n",
       " (['can', 'you', 'ideas'], 'express'),\n",
       " (['express', 'can', 'you'], ','),\n",
       " ([',', 'express', 'can'], 'and'),\n",
       " (['and', ',', 'express'], 'that'),\n",
       " (['that', 'and', ','], 'in'),\n",
       " (['in', 'that', 'and'], 'turn'),\n",
       " (['turn', 'in', 'that'], 'will'),\n",
       " (['will', 'turn', 'in'], 'constrain'),\n",
       " (['constrain', 'will', 'turn'], 'which'),\n",
       " (['which', 'constrain', 'will'], 'ideas'),\n",
       " (['ideas', 'which', 'constrain'], 'you'),\n",
       " (['you', 'ideas', 'which'], 'have'),\n",
       " (['have', 'you', 'ideas'], '.'),\n",
       " (['.', 'have', 'you'], 'But'),\n",
       " (['But', '.', 'have'], 'if'),\n",
       " (['if', 'But', '.'], 'you'),\n",
       " (['you', 'if', 'But'], 'surround'),\n",
       " (['surround', 'you', 'if'], 'yourself'),\n",
       " (['yourself', 'surround', 'you'], 'with'),\n",
       " (['with', 'yourself', 'surround'], 'independent'),\n",
       " (['independent', 'with', 'yourself'], '-'),\n",
       " (['-', 'independent', 'with'], 'minded'),\n",
       " (['minded', '-', 'independent'], 'people'),\n",
       " (['people', 'minded', '-'], ','),\n",
       " ([',', 'people', 'minded'], 'you'),\n",
       " (['you', ',', 'people'], 'll'),\n",
       " (['ll', 'you', ','], 'have'),\n",
       " (['have', 'll', 'you'], 'the'),\n",
       " (['the', 'have', 'll'], 'opposite'),\n",
       " (['opposite', 'the', 'have'], 'experience'),\n",
       " (['experience', 'opposite', 'the'], ':'),\n",
       " ([':', 'experience', 'opposite'], 'hearing'),\n",
       " (['hearing', ':', 'experience'], 'other'),\n",
       " (['other', 'hearing', ':'], 'people'),\n",
       " (['people', 'other', 'hearing'], 'say'),\n",
       " (['say', 'people', 'other'], 'surprising'),\n",
       " (['surprising', 'say', 'people'], 'things'),\n",
       " (['things', 'surprising', 'say'], 'will'),\n",
       " (['will', 'things', 'surprising'], 'encourage'),\n",
       " (['encourage', 'will', 'things'], 'you'),\n",
       " (['you', 'encourage', 'will'], 'to'),\n",
       " (['to', 'you', 'encourage'], ','),\n",
       " ([',', 'to', 'you'], 'and'),\n",
       " (['and', ',', 'to'], 'to'),\n",
       " (['to', 'and', ','], 'think'),\n",
       " (['think', 'to', 'and'], 'of'),\n",
       " (['of', 'think', 'to'], 'more'),\n",
       " (['more', 'of', 'think'], '.'),\n",
       " (['.', 'more', 'of'], 'Because'),\n",
       " (['Because', '.', 'more'], 'the'),\n",
       " (['the', 'Because', '.'], 'independent'),\n",
       " (['independent', 'the', 'Because'], '-'),\n",
       " (['-', 'independent', 'the'], 'minded'),\n",
       " (['minded', '-', 'independent'], 'find'),\n",
       " (['find', 'minded', '-'], 'it'),\n",
       " (['it', 'find', 'minded'], 'uncomfortable'),\n",
       " (['uncomfortable', 'it', 'find'], 'to'),\n",
       " (['to', 'uncomfortable', 'it'], 'be'),\n",
       " (['be', 'to', 'uncomfortable'], 'surrounded'),\n",
       " (['surrounded', 'be', 'to'], 'by'),\n",
       " (['by', 'surrounded', 'be'], 'conventional'),\n",
       " (['conventional', 'by', 'surrounded'], '-'),\n",
       " (['-', 'conventional', 'by'], 'minded'),\n",
       " (['minded', '-', 'conventional'], 'people'),\n",
       " (['people', 'minded', '-'], ','),\n",
       " ([',', 'people', 'minded'], 'they'),\n",
       " (['they', ',', 'people'], 'tend'),\n",
       " (['tend', 'they', ','], 'to'),\n",
       " (['to', 'tend', 'they'], 'self'),\n",
       " (['self', 'to', 'tend'], '-'),\n",
       " (['-', 'self', 'to'], 'segregate'),\n",
       " (['segregate', '-', 'self'], 'once'),\n",
       " (['once', 'segregate', '-'], 'they'),\n",
       " (['they', 'once', 'segregate'], 'have'),\n",
       " (['have', 'they', 'once'], 'a'),\n",
       " (['a', 'have', 'they'], 'chance'),\n",
       " (['chance', 'a', 'have'], 'to'),\n",
       " (['to', 'chance', 'a'], '.'),\n",
       " (['.', 'to', 'chance'], 'The'),\n",
       " (['The', '.', 'to'], 'problem'),\n",
       " (['problem', 'The', '.'], 'with'),\n",
       " (['with', 'problem', 'The'], 'high'),\n",
       " (['high', 'with', 'problem'], 'school'),\n",
       " (['school', 'high', 'with'], 'is'),\n",
       " (['is', 'school', 'high'], 'that'),\n",
       " (['that', 'is', 'school'], 'they'),\n",
       " (['they', 'that', 'is'], 'have'),\n",
       " (['have', 'they', 'that'], 'nt'),\n",
       " (['nt', 'have', 'they'], 'yet'),\n",
       " (['yet', 'nt', 'have'], 'had'),\n",
       " (['had', 'yet', 'nt'], 'a'),\n",
       " (['a', 'had', 'yet'], 'chance'),\n",
       " (['chance', 'a', 'had'], 'to'),\n",
       " (['to', 'chance', 'a'], '.'),\n",
       " (['.', 'to', 'chance'], 'Plus'),\n",
       " (['Plus', '.', 'to'], 'high'),\n",
       " (['high', 'Plus', '.'], 'school'),\n",
       " (['school', 'high', 'Plus'], 'tends'),\n",
       " (['tends', 'school', 'high'], 'to'),\n",
       " (['to', 'tends', 'school'], 'be'),\n",
       " (['be', 'to', 'tends'], 'an'),\n",
       " (['an', 'be', 'to'], 'inward'),\n",
       " ...]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa94ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
